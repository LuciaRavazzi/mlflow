{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **How to use MlFlow with LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the same tools that we have seen for traditional models:\n",
    "- **Experiment tracking** collects models, prompts, traces and metrics in a single place. It collects further information related to document retrieval, data queries and tool calls. \n",
    "- **Experiment Tracing**: collects runtime information like retrieval, tool calls, data queries etc. \n",
    "- **Packaging**: manage moving pieces of GenAI systems\n",
    "- **Evaluation**: in this way it's possible to compare different models using latency, answer correctness etc. \n",
    "- **Model Serving**: they can be deployed on Kubernetes cluster, cloud providers etc. \n",
    "- **Prompt Engineering UI** is used to modify the prompt in order to obtain better results. \n",
    "- **MLflow AI Gateway**: for unified endpoint for deploying\n",
    "\n",
    "The main difference between MlFlow serving and the MLflow AI Gateway is that the first one allows us to query the model through a HTTP request while the latter is an advanced service built on top of MLflow that allows easier deployment, scaling, and management of machine learning models across different environments and infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tracing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os \n",
    "\n",
    "# os.environ[\"MLFLOW_TRACKING_TOKEN\"] = \"\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/486592786572829437', creation_time=1742222202058, experiment_id='486592786572829437', last_update_time=1742222202058, lifecycle_stage='active', name='Ollama-v3', tags={}>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Enable auto-tracing for OpenAI\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Optional: Set a tracking URI and an experiment\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Ollama-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=35cde92d4d24404488d9fc7e4c91df7a&amp;experiment_id=486592786572829437&amp;version=2.20.4\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(request_id=35cde92d4d24404488d9fc7e4c91df7a)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",  # The local Ollama REST endpoint\n",
    "    api_key=\"dummy\",  # Required to instantiate OpenAI client, it can be a random string\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama3.2:1b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a science teacher.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Why is the sky blue?\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MlFlow traces is characterized by:\n",
    "- TraceInfo: every features related to experiment and runs such as the duration etc.\n",
    "- TraceData: each information related to runtime. Each trace is made up of multiple spans: they record key, critical data about each of the steps within your genai application. \n",
    "\n",
    "It's possible to define the spans with the decorator @mlflow.trace related to the function that will be called within the application or mlflow.start_span() to customize the span.\n",
    "\n",
    "A trace is like a run that store information of the execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "@mlflow.trace(span_type=\"func\", attributes={\"key\": \"value\"})\n",
    "def add_1(x):\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "@mlflow.trace(span_type=\"func\", attributes={\"key1\": \"value1\"})\n",
    "def minus_1(x):\n",
    "    return x - 1\n",
    "\n",
    "\n",
    "@mlflow.trace(name=\"Trace Test\")\n",
    "def trace_test(x):\n",
    "    step1 = add_1(x)\n",
    "    return minus_1(step1)\n",
    "\n",
    "\n",
    "trace_test(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>trace</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>status</th>\n",
       "      <th>execution_time_ms</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>request_metadata</th>\n",
       "      <th>spans</th>\n",
       "      <th>tags</th>\n",
       "      <th>assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e12f87c5ca0d4d66a52706bbf5a1d569</td>\n",
       "      <td>Trace(request_id=e12f87c5ca0d4d66a52706bbf5a1d...</td>\n",
       "      <td>1742222240588</td>\n",
       "      <td>TraceStatus.OK</td>\n",
       "      <td>16471</td>\n",
       "      <td>{'model': 'llama3.2:1b', 'messages': [{'role':...</td>\n",
       "      <td>{'id': 'chatcmpl-690', 'choices': [{'finish_re...</td>\n",
       "      <td>{'mlflow.traceInputs': '{\"model\": \"llama3.2:1b...</td>\n",
       "      <td>[{'name': 'Completions', 'context': {'span_id'...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'mlflow-artifacts:...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>248fd79e3ac148e1bfbedb3712b945fc</td>\n",
       "      <td>Trace(request_id=248fd79e3ac148e1bfbedb3712b94...</td>\n",
       "      <td>1742222204166</td>\n",
       "      <td>TraceStatus.OK</td>\n",
       "      <td>14722</td>\n",
       "      <td>{'model': 'llama3.2:1b', 'messages': [{'role':...</td>\n",
       "      <td>{'id': 'chatcmpl-897', 'choices': [{'finish_re...</td>\n",
       "      <td>{'mlflow.traceInputs': '{\"model\": \"llama3.2:1b...</td>\n",
       "      <td>[{'name': 'Completions', 'context': {'span_id'...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'mlflow-artifacts:...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         request_id  \\\n",
       "0  e12f87c5ca0d4d66a52706bbf5a1d569   \n",
       "1  248fd79e3ac148e1bfbedb3712b945fc   \n",
       "\n",
       "                                               trace   timestamp_ms  \\\n",
       "0  Trace(request_id=e12f87c5ca0d4d66a52706bbf5a1d...  1742222240588   \n",
       "1  Trace(request_id=248fd79e3ac148e1bfbedb3712b94...  1742222204166   \n",
       "\n",
       "           status  execution_time_ms  \\\n",
       "0  TraceStatus.OK              16471   \n",
       "1  TraceStatus.OK              14722   \n",
       "\n",
       "                                             request  \\\n",
       "0  {'model': 'llama3.2:1b', 'messages': [{'role':...   \n",
       "1  {'model': 'llama3.2:1b', 'messages': [{'role':...   \n",
       "\n",
       "                                            response  \\\n",
       "0  {'id': 'chatcmpl-690', 'choices': [{'finish_re...   \n",
       "1  {'id': 'chatcmpl-897', 'choices': [{'finish_re...   \n",
       "\n",
       "                                    request_metadata  \\\n",
       "0  {'mlflow.traceInputs': '{\"model\": \"llama3.2:1b...   \n",
       "1  {'mlflow.traceInputs': '{\"model\": \"llama3.2:1b...   \n",
       "\n",
       "                                               spans  \\\n",
       "0  [{'name': 'Completions', 'context': {'span_id'...   \n",
       "1  [{'name': 'Completions', 'context': {'span_id'...   \n",
       "\n",
       "                                                tags assessments  \n",
       "0  {'mlflow.artifactLocation': 'mlflow-artifacts:...          []  \n",
       "1  {'mlflow.artifactLocation': 'mlflow-artifacts:...          []  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=e12f87c5ca0d4d66a52706bbf5a1d569&amp;experiment_id=486592786572829437&amp;trace_id=248fd79e3ac148e1bfbedb3712b945fc&amp;experiment_id=486592786572829437&amp;version=2.20.4\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(request_id=e12f87c5ca0d4d66a52706bbf5a1d569), Trace(request_id=248fd79e3ac148e1bfbedb3712b945fc)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.search_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and traces can be mixed with mlflow.start_run and mlflow.start_span. Indeed, in that case, a new trace will be created inside a run.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
