{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **How to use MlFlow with LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the same tools that we have seen for traditional models:\n",
    "- **Experiment tracking** collects models, prompts, traces and metrics in a single place. It collects further information related to document retrieval, data queries and tool calls. \n",
    "- **Experiment tracing**: collects runtime information like retrieval, tool calls, data queries etc. \n",
    "- **Packaging**: manage moving pieces of GenAI systems\n",
    "- **Evaluation**: in this way it's possible to compare different models using latency, answer correctness etc. \n",
    "- **Model Serving**: they can be deployed on Kubernetes cluster, cloud providers etc. \n",
    "- **Prompt Engineering UI** is used to modify the prompt in order to obtain better results. \n",
    "- **MLflow AI Gateway**: for unified endpoint for deploying\n",
    "\n",
    "The main difference between MlFlow serving and the MLflow AI Gateway is that the first one allows us to query the model through a HTTP request while the latter is an advanced service built on top of MLflow that allows easier deployment, scaling, and management of machine learning models across different environments and infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tracing**\n",
    "\n",
    "After setting an experiment, a Trace works as a run but with more information. \n",
    "\n",
    "MlFlow trace is characterized by:\n",
    "- TraceInfo: the Trace Info within MLflow's tracing feature aims to provide a lightweight snapshot of critical data about the overall trace. This includes the logistical information about the trace, such as the experiment_id, providing the storage location for the trace, as well as trace-level data such as start time and total execution time. The Trace Info also includes tags and status information for the trace as a whole.\n",
    "- TraceData: The Trace Data within MLflow's tracing feature provides the core of the trace information. Within this object is a list of Span objects that represent the individual steps of the trace. These **spans** are associated with one another in a hierarchical relationship, providing a clear order-of-operations linkage of what happened within your application during the trace. ach Span object contains information about the step being instrumented, including the span_id, name, start_time, parent_id, status, inputs, outputs, attributes, and events.\n",
    "\n",
    "You can track both run information and trace during the same run: a new run will be created and the traces are stored within the race.\n",
    "\n",
    "It's possible to define the spans with the decorator @mlflow.trace related to the function that will be called within the application or mlflow.start_span() to customize the span.\n",
    "\n",
    "A trace is like a run that store more information related to the execution. \n",
    "\n",
    "Traces can be explored through MLFlow UI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Enable auto-tracing\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Optional: Set a tracking URI and an experiment\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "# Ollama offers open-source models\n",
    "exp = mlflow.set_experiment(\"Ollama-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",  # The local Ollama REST endpoint\n",
    "    api_key=\"dummy\",  # Required to instantiate OpenAI client, it can be a random string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run nervous-stork-873 at: http://localhost:5000/#/experiments/923280573827939376/runs/06fe450af8284586b66654689c0569e6\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/923280573827939376\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=5374367d987e4d53800ee55bb18c4bd0&amp;experiment_id=923280573827939376&amp;version=2.21.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(request_id=5374367d987e4d53800ee55bb18c4bd0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In this case, the trace appears both in the run and trace tab but they are the same\n",
    "\n",
    "with mlflow.start_run():\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"llama3.2:1b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a science teacher.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Why is the sky blue?\"},\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        max_tokens=1000,   \n",
    "        # stream = True # streaming data are stored in Event tab    \n",
    "    )\n",
    "    \n",
    "    mlflow.log_param('p', 1)\n",
    "    \n",
    "    # for chunk in stream:\n",
    "    #     print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Trace Customization**\n",
    "\n",
    "Using the autologging, the span type is defined by default. On the other hand, you can define the span type on your own:\n",
    "- @mlflow.trace(span_type=SpanType.RETRIEVER) using predefined spans type\n",
    "- with mlflow.start_span(name = 'add', span_type = 'MATH') is a new span type\n",
    "\n",
    "You can mix autologging with span description.\n",
    "\n",
    "For multiple invocations, set the same session_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run big-tern-304 at: http://localhost:5000/#/experiments/923280573827939376/runs/37f775059bc245bba9d9b285837bb52e\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/923280573827939376\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=7e529c6708b64e079f928d9940394f1b&amp;experiment_id=923280573827939376&amp;version=2.21.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(request_id=7e529c6708b64e079f928d9940394f1b)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import mlflow\n",
    "from mlflow.entities import SpanType\n",
    "\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "with mlflow.start_run() as run: # otherwise Exception\n",
    "    span = mlflow.start_span(\"train_model\")\n",
    "    # Define the tool function. Decorate it with `@mlflow.trace` to create a span for its execution.\n",
    "    @mlflow.trace(name = \"GetWeather\", span_type=SpanType.TOOL,  attributes={\"Description\": \"Get wetaher for a given city\"})\n",
    "    def get_weather(city: str) -> str:\n",
    "        if city == \"Tokyo\":\n",
    "            return \"sunny\"\n",
    "        elif city == \"Paris\":\n",
    "            return \"rainy\"\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_weather\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\"city\": {\"type\": \"string\"}},\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    _tool_functions = {\"get_weather\": get_weather}\n",
    "\n",
    "\n",
    "    # Define a simple tool calling agent\n",
    "    @mlflow.trace(span_type=SpanType.AGENT)\n",
    "    def run_tool_agent(question: str):\n",
    "        mlflow.update_current_trace(tags={\"Agent\": \"Chat\"})\n",
    "        messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "        # Invoke the model with the given question and available tools\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama3.2:1b\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "        )\n",
    "        ai_msg = response.choices[0].message\n",
    "        messages.append(ai_msg)\n",
    "\n",
    "        # If the model request tool call(s), invoke the function with the specified arguments\n",
    "        if tool_calls := ai_msg.tool_calls:\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                if tool_func := _tool_functions.get(function_name):\n",
    "                    args = json.loads(tool_call.function.arguments)\n",
    "                    tool_result = tool_func(**args)\n",
    "                else:\n",
    "                    raise RuntimeError(\"An invalid tool is returned from the assistant!\")\n",
    "\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"content\": tool_result,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # Sent the tool results to the model and get a new response\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"llama3.2:1b\", messages=messages\n",
    "            )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    # Run the tool calling agent\n",
    "    question = \"What's the weather like in Paris today?\"\n",
    "    answer = run_tool_agent(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query Traces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>trace</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>status</th>\n",
       "      <th>execution_time_ms</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>request_metadata</th>\n",
       "      <th>spans</th>\n",
       "      <th>tags</th>\n",
       "      <th>assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98ee4daa5daa40e2bbfcc5b637d59045</td>\n",
       "      <td>Trace(request_id=98ee4daa5daa40e2bbfcc5b637d59...</td>\n",
       "      <td>1742313806499</td>\n",
       "      <td>TraceStatus.OK</td>\n",
       "      <td>5587</td>\n",
       "      <td>{'question': 'What's the weather like in Paris...</td>\n",
       "      <td>It seems that the weather in Paris is currentl...</td>\n",
       "      <td>{'mlflow.sourceRun': 'b8ef5bfcb527470bba0ee2c9...</td>\n",
       "      <td>[{'name': 'run_tool_agent', 'context': {'span_...</td>\n",
       "      <td>{'Agent': 'Chat', 'mlflow.artifactLocation': '...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70d5ffcbf2c14c7c973df76b03449b86</td>\n",
       "      <td>Trace(request_id=70d5ffcbf2c14c7c973df76b03449...</td>\n",
       "      <td>1742313778413</td>\n",
       "      <td>TraceStatus.ERROR</td>\n",
       "      <td>45</td>\n",
       "      <td>{'question': 'What's the weather like in Paris...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'mlflow.sourceRun': 'bc8795352ab74029a37ebf07...</td>\n",
       "      <td>[{'name': 'run_tool_agent', 'context': {'span_...</td>\n",
       "      <td>{'Agent': 'Chat', 'mlflow.artifactLocation': '...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b2743314768543e8a3d6414fa368ca0b</td>\n",
       "      <td>Trace(request_id=b2743314768543e8a3d6414fa368c...</td>\n",
       "      <td>1742313776289</td>\n",
       "      <td>TraceStatus.ERROR</td>\n",
       "      <td>41</td>\n",
       "      <td>{'question': 'What's the weather like in Paris...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'mlflow.sourceRun': 'a637d4de6d004e12a2e91313...</td>\n",
       "      <td>[{'name': 'run_tool_agent', 'context': {'span_...</td>\n",
       "      <td>{'Agent': 'Chat', 'mlflow.artifactLocation': '...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5374367d987e4d53800ee55bb18c4bd0</td>\n",
       "      <td>Trace(request_id=5374367d987e4d53800ee55bb18c4...</td>\n",
       "      <td>1742313614432</td>\n",
       "      <td>TraceStatus.OK</td>\n",
       "      <td>14222</td>\n",
       "      <td>{'model': 'llama3.2:1b', 'messages': [{'role':...</td>\n",
       "      <td>{'id': 'chatcmpl-307', 'choices': [{'finish_re...</td>\n",
       "      <td>{'mlflow.sourceRun': '06fe450af8284586b6665468...</td>\n",
       "      <td>[{'name': 'Completions', 'context': {'span_id'...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'mlflow-artifacts:...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         request_id  \\\n",
       "0  98ee4daa5daa40e2bbfcc5b637d59045   \n",
       "1  70d5ffcbf2c14c7c973df76b03449b86   \n",
       "2  b2743314768543e8a3d6414fa368ca0b   \n",
       "3  5374367d987e4d53800ee55bb18c4bd0   \n",
       "\n",
       "                                               trace   timestamp_ms  \\\n",
       "0  Trace(request_id=98ee4daa5daa40e2bbfcc5b637d59...  1742313806499   \n",
       "1  Trace(request_id=70d5ffcbf2c14c7c973df76b03449...  1742313778413   \n",
       "2  Trace(request_id=b2743314768543e8a3d6414fa368c...  1742313776289   \n",
       "3  Trace(request_id=5374367d987e4d53800ee55bb18c4...  1742313614432   \n",
       "\n",
       "              status  execution_time_ms  \\\n",
       "0     TraceStatus.OK               5587   \n",
       "1  TraceStatus.ERROR                 45   \n",
       "2  TraceStatus.ERROR                 41   \n",
       "3     TraceStatus.OK              14222   \n",
       "\n",
       "                                             request  \\\n",
       "0  {'question': 'What's the weather like in Paris...   \n",
       "1  {'question': 'What's the weather like in Paris...   \n",
       "2  {'question': 'What's the weather like in Paris...   \n",
       "3  {'model': 'llama3.2:1b', 'messages': [{'role':...   \n",
       "\n",
       "                                            response  \\\n",
       "0  It seems that the weather in Paris is currentl...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  {'id': 'chatcmpl-307', 'choices': [{'finish_re...   \n",
       "\n",
       "                                    request_metadata  \\\n",
       "0  {'mlflow.sourceRun': 'b8ef5bfcb527470bba0ee2c9...   \n",
       "1  {'mlflow.sourceRun': 'bc8795352ab74029a37ebf07...   \n",
       "2  {'mlflow.sourceRun': 'a637d4de6d004e12a2e91313...   \n",
       "3  {'mlflow.sourceRun': '06fe450af8284586b6665468...   \n",
       "\n",
       "                                               spans  \\\n",
       "0  [{'name': 'run_tool_agent', 'context': {'span_...   \n",
       "1  [{'name': 'run_tool_agent', 'context': {'span_...   \n",
       "2  [{'name': 'run_tool_agent', 'context': {'span_...   \n",
       "3  [{'name': 'Completions', 'context': {'span_id'...   \n",
       "\n",
       "                                                tags assessments  \n",
       "0  {'Agent': 'Chat', 'mlflow.artifactLocation': '...          []  \n",
       "1  {'Agent': 'Chat', 'mlflow.artifactLocation': '...          []  \n",
       "2  {'Agent': 'Chat', 'mlflow.artifactLocation': '...          []  \n",
       "3  {'mlflow.artifactLocation': 'mlflow-artifacts:...          []  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=98ee4daa5daa40e2bbfcc5b637d59045&amp;experiment_id=923280573827939376&amp;trace_id=70d5ffcbf2c14c7c973df76b03449b86&amp;experiment_id=923280573827939376&amp;trace_id=b2743314768543e8a3d6414fa368ca0b&amp;experiment_id=923280573827939376&amp;trace_id=5374367d987e4d53800ee55bb18c4bd0&amp;experiment_id=923280573827939376&amp;version=2.21.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(request_id=98ee4daa5daa40e2bbfcc5b637d59045), Trace(request_id=70d5ffcbf2c14c7c973df76b03449b86), Trace(request_id=b2743314768543e8a3d6414fa368ca0b), Trace(request_id=5374367d987e4d53800ee55bb18c4bd0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tables with information about request_id\n",
    "mlflow.search_traces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Trace(request_id=7e529c6708b64e079f928d9940394f1b),\n",
       " Trace(request_id=79231af57b3d4ea698f5d959e8facac4),\n",
       " Trace(request_id=7670eef0bd324d4c8e9c921df1b255bf),\n",
       " Trace(request_id=98ee4daa5daa40e2bbfcc5b637d59045),\n",
       " Trace(request_id=70d5ffcbf2c14c7c973df76b03449b86),\n",
       " Trace(request_id=b2743314768543e8a3d6414fa368ca0b),\n",
       " Trace(request_id=5374367d987e4d53800ee55bb18c4bd0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=7e529c6708b64e079f928d9940394f1b&amp;experiment_id=923280573827939376&amp;trace_id=79231af57b3d4ea698f5d959e8facac4&amp;experiment_id=923280573827939376&amp;trace_id=7670eef0bd324d4c8e9c921df1b255bf&amp;experiment_id=923280573827939376&amp;trace_id=98ee4daa5daa40e2bbfcc5b637d59045&amp;experiment_id=923280573827939376&amp;trace_id=70d5ffcbf2c14c7c973df76b03449b86&amp;experiment_id=923280573827939376&amp;trace_id=b2743314768543e8a3d6414fa368ca0b&amp;experiment_id=923280573827939376&amp;trace_id=5374367d987e4d53800ee55bb18c4bd0&amp;experiment_id=923280573827939376&amp;version=2.21.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(request_id=7e529c6708b64e079f928d9940394f1b), Trace(request_id=79231af57b3d4ea698f5d959e8facac4), Trace(request_id=7670eef0bd324d4c8e9c921df1b255bf), Trace(request_id=98ee4daa5daa40e2bbfcc5b637d59045), Trace(request_id=70d5ffcbf2c14c7c973df76b03449b86), Trace(request_id=b2743314768543e8a3d6414fa368ca0b), Trace(request_id=5374367d987e4d53800ee55bb18c4bd0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list of request_id\n",
    "\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "client.search_traces(experiment_ids=[exp.experiment_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Trace(request_id=7e529c6708b64e079f928d9940394f1b),\n",
       " Trace(request_id=79231af57b3d4ea698f5d959e8facac4),\n",
       " Trace(request_id=7670eef0bd324d4c8e9c921df1b255bf),\n",
       " Trace(request_id=98ee4daa5daa40e2bbfcc5b637d59045),\n",
       " Trace(request_id=70d5ffcbf2c14c7c973df76b03449b86),\n",
       " Trace(request_id=b2743314768543e8a3d6414fa368ca0b)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=7e529c6708b64e079f928d9940394f1b&amp;experiment_id=923280573827939376&amp;trace_id=79231af57b3d4ea698f5d959e8facac4&amp;experiment_id=923280573827939376&amp;trace_id=7670eef0bd324d4c8e9c921df1b255bf&amp;experiment_id=923280573827939376&amp;trace_id=98ee4daa5daa40e2bbfcc5b637d59045&amp;experiment_id=923280573827939376&amp;trace_id=70d5ffcbf2c14c7c973df76b03449b86&amp;experiment_id=923280573827939376&amp;trace_id=b2743314768543e8a3d6414fa368ca0b&amp;experiment_id=923280573827939376&amp;version=2.21.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(request_id=7e529c6708b64e079f928d9940394f1b), Trace(request_id=79231af57b3d4ea698f5d959e8facac4), Trace(request_id=7670eef0bd324d4c8e9c921df1b255bf), Trace(request_id=98ee4daa5daa40e2bbfcc5b637d59045), Trace(request_id=70d5ffcbf2c14c7c973df76b03449b86), Trace(request_id=b2743314768543e8a3d6414fa368ca0b)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client.search_traces(\n",
    "    experiment_ids=[exp.experiment_id],\n",
    "    filter_string=\"trace.name = 'run_tool_agent'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Trace(request_id=7e529c6708b64e079f928d9940394f1b),\n",
       " Trace(request_id=79231af57b3d4ea698f5d959e8facac4),\n",
       " Trace(request_id=7670eef0bd324d4c8e9c921df1b255bf),\n",
       " Trace(request_id=98ee4daa5daa40e2bbfcc5b637d59045),\n",
       " Trace(request_id=70d5ffcbf2c14c7c973df76b03449b86),\n",
       " Trace(request_id=b2743314768543e8a3d6414fa368ca0b)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=7e529c6708b64e079f928d9940394f1b&amp;experiment_id=923280573827939376&amp;trace_id=79231af57b3d4ea698f5d959e8facac4&amp;experiment_id=923280573827939376&amp;trace_id=7670eef0bd324d4c8e9c921df1b255bf&amp;experiment_id=923280573827939376&amp;trace_id=98ee4daa5daa40e2bbfcc5b637d59045&amp;experiment_id=923280573827939376&amp;trace_id=70d5ffcbf2c14c7c973df76b03449b86&amp;experiment_id=923280573827939376&amp;trace_id=b2743314768543e8a3d6414fa368ca0b&amp;experiment_id=923280573827939376&amp;version=2.21.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(request_id=7e529c6708b64e079f928d9940394f1b), Trace(request_id=79231af57b3d4ea698f5d959e8facac4), Trace(request_id=7670eef0bd324d4c8e9c921df1b255bf), Trace(request_id=98ee4daa5daa40e2bbfcc5b637d59045), Trace(request_id=70d5ffcbf2c14c7c973df76b03449b86), Trace(request_id=b2743314768543e8a3d6414fa368ca0b)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client.search_traces(\n",
    "    experiment_ids=[exp.experiment_id],\n",
    "    filter_string=\"tag.Agent = 'Chat'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search_traces(\n",
    "    experiment_ids=[exp.experiment_id],\n",
    "    filter_string=\"tag.Status = 'OK'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and traces can be mixed with mlflow.start_run and mlflow.start_span. Indeed, in that case, a new trace will be created inside a run.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
